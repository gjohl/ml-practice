{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ab89eef-9c93-43f3-8665-56c9efbd85c7",
   "metadata": {},
   "source": [
    "# Lesson 5: Linear model and Neural Network From Scratch\n",
    "A notebook based on Lesson 5 of the Fast AI course.\n",
    "\n",
    "In this notebook, we will train a linear model from scratch using basic pytorch tensors.\n",
    "This follows a similar process to the spreadsheet approach from Lesson 3, [here](https://docs.google.com/spreadsheets/d/1hma4bTEFuiS483djqE5dPoLlbsSQOTioqMzsesZGUGI/edit?usp=sharing)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78bc27d-00bf-49bf-8bcf-1c338adb131a",
   "metadata": {},
   "source": [
    "## 0. Set up\n",
    "Download the source data from Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "681808f6-761a-44d6-b5ae-831868fa47a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/gurp/.kaggle/kaggle.json'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "\n",
    "import kaggle\n",
    "\n",
    "\n",
    "DATA_DIR = Path().absolute().parents[1] / 'datasets' / 'fastai' / 'lesson5'\n",
    "DATA_FNAME = 'titanic'\n",
    "\n",
    "if not DATA_DIR.exists():\n",
    "    kaggle.api.competition_download_cli(str(DATA_FNAME), path=DATA_DIR)\n",
    "    zipfile.ZipFile(f'{DATA_DIR / DATA_FNAME}.zip').extractall(DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d362e1d-1b70-4703-b9e4-f837c9cd5ec0",
   "metadata": {},
   "source": [
    "## 1. Feature engineering\n",
    "Clean the data, impute missing values and calcualte some meaningful features to train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57c0eeed-6ea9-4d81-96a6-03be670a30a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7be02555-64eb-4c8a-a781-f112f55f0e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(DATA_DIR / 'train.csv')\n",
    "test_df = pd.read_csv(DATA_DIR / 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e621991-b3e7-4848-8d08-76d94f73f715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11d927fc-a98b-4c08-b9dd-0abcc4cf4d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_cols = ['AgeNorm', 'SibSp', 'Parch', 'Family', 'Alone', 'LogFare', 'TicketFreq']\n",
    "categorical_cols = ['Pclass', 'Sex', 'Embarked', 'Deck', 'Title']\n",
    "    \n",
    "\n",
    "def calculate_features(df):\n",
    "    \"\"\"Add engineered features for the titanic dataset.\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Min-max scaler on Age\n",
    "    df['AgeNorm'] = df['Age'].fillna(df['Age'].mean()) / df['Age'].max()\n",
    "\n",
    "    # Log of Fares to tame the long tail\n",
    "    df['LogFare'] = np.log1p(df['Fare'])\n",
    "\n",
    "    # Group Cabins by Deck\n",
    "    df['Cabin'].fillna(df['Cabin'].mode().iloc[0], inplace=True)\n",
    "    df['Deck'] = df['Cabin'].str[0].map(dict(A=\"ABC\", B=\"ABC\", C=\"ABC\", D=\"DE\", E=\"DE\", F=\"FG\", G=\"FG\")).fillna(\"Other\")\n",
    "\n",
    "    # Features based on family members\n",
    "    df['Family'] = df['SibSp'] + df['Parch']\n",
    "    df['Alone'] = df['Family'] == 0\n",
    "\n",
    "    # Did multiple people travel on the same ticket\n",
    "    df['TicketFreq'] = df.groupby('Ticket')['Ticket'].transform('count')\n",
    "\n",
    "    # Use just the title portion of the Name field\n",
    "    df['Title'] = df['Name'].str.split(', ', expand=True)[1].str.split('. ', expand=True)[0]\n",
    "    df['Title'] = df['Title'].map({'Mr': 'Mr', 'Miss': 'Miss', 'Mrs': 'Mrs', 'Master': 'Master'}).fillna(\"Other\")\n",
    "\n",
    "    # One-hot encode categorical variables\n",
    "    categorical_cols = ['Pclass', 'Sex', 'Embarked', 'Deck', 'Title']\n",
    "    df['Embarked'].fillna(df['Embarked'].mode().iloc[0], inplace=True)\n",
    "    df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "    df['const'] = 1\n",
    "\n",
    "    # Filter the output columns\n",
    "    categorical_cols_output = []\n",
    "    for cat_col in categorical_cols:\n",
    "        categorical_cols_output.extend([k for k in df.columns if f'{cat_col}_' in k])\n",
    "    output_cols = continuous_cols + categorical_cols_output\n",
    "\n",
    "    return df[output_cols] * 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00fe4391-7b2c-448f-9d00-5876169a02fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AgeNorm</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Family</th>\n",
       "      <th>Alone</th>\n",
       "      <th>LogFare</th>\n",
       "      <th>TicketFreq</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Deck_DE</th>\n",
       "      <th>Deck_FG</th>\n",
       "      <th>Deck_Other</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.110213</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.280593</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.188856</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.990834</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.202765</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AgeNorm  SibSp  Parch  Family  Alone   LogFare  TicketFreq  Pclass_2  \\\n",
       "0   0.2750    1.0    0.0     1.0    0.0  2.110213         1.0       0.0   \n",
       "1   0.4750    1.0    0.0     1.0    0.0  4.280593         1.0       0.0   \n",
       "2   0.3250    0.0    0.0     0.0    1.0  2.188856         1.0       0.0   \n",
       "3   0.4375    1.0    0.0     1.0    0.0  3.990834         2.0       0.0   \n",
       "4   0.4375    0.0    0.0     0.0    1.0  2.202765         1.0       0.0   \n",
       "\n",
       "   Pclass_3  Sex_male  Embarked_Q  Embarked_S  Deck_DE  Deck_FG  Deck_Other  \\\n",
       "0       1.0       1.0         0.0         1.0      0.0      0.0         0.0   \n",
       "1       0.0       0.0         0.0         0.0      0.0      0.0         0.0   \n",
       "2       1.0       0.0         0.0         1.0      0.0      0.0         0.0   \n",
       "3       0.0       0.0         0.0         1.0      0.0      0.0         0.0   \n",
       "4       1.0       1.0         0.0         1.0      0.0      0.0         0.0   \n",
       "\n",
       "   Title_Miss  Title_Mr  Title_Mrs  Title_Other  \n",
       "0         0.0       1.0        0.0          0.0  \n",
       "1         0.0       0.0        1.0          0.0  \n",
       "2         1.0       0.0        0.0          0.0  \n",
       "3         0.0       0.0        1.0          0.0  \n",
       "4         0.0       1.0        0.0          0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = calculate_features(train_df)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1511c571-db9d-4917-b9da-6df96953d4a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    1.0\n",
       "2    1.0\n",
       "3    1.0\n",
       "4    0.0\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train_df['Survived'] * 1.\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c80bde4-364d-4ded-88e0-76a2ff66af36",
   "metadata": {},
   "source": [
    "## 2. Train a linear model\n",
    "Train a linear model \"from scratch\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c85170-e957-4068-a08b-6400d57cc4e1",
   "metadata": {},
   "source": [
    "### 2.1. Initialise random weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a078dd8-8ce5-407b-9536-a5aa4fbcd510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66cf138b-99e0-46b1-afab-def6f0565950",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = X_train.shape[1]\n",
    "num_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5aa109f-c281-4977-9b37-de4693e9f135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_weights(num_layers, num_features):\n",
    "    weights = torch.rand([num_layers, num_features]) - 0.5\n",
    "    weights.requires_grad_()\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afc9370e-061d-47f8-9702-04fd5f4379aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3417,  0.4206,  0.1409,  0.4548,  0.2176,  0.3695,  0.2355, -0.0815,\n",
       "          0.3598,  0.3943,  0.1020, -0.3897,  0.1433,  0.3704, -0.1163, -0.2272,\n",
       "          0.0212,  0.3592,  0.1844]], requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = initialise_weights(num_layers, num_features)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de7e8a8-a98b-44a3-9e83-a37aef06c02b",
   "metadata": {},
   "source": [
    "### 2.2. Define the model and loss function\n",
    "This is just a linear model with MAE loss function to start with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbd56beb-28d1-402f-9aa3-abd7a450de4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(predictions, actual):\n",
    "    \"\"\"Mean Absolute Error\"\"\"\n",
    "    return (predictions - actual).abs().mean()\n",
    "    \n",
    "\n",
    "def calculate_predictions(features, weights):\n",
    "    \"\"\"Linear model to calculate predictions.\"\"\"\n",
    "    return (features @ weights.T).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bb50f37-d43f-4449-9569-2d3a4ede3d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2750, 1.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
       "        [0.4750, 1.0000, 0.0000,  ..., 0.0000, 1.0000, 0.0000],\n",
       "        [0.3250, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.3712, 1.0000, 2.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.3250, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
       "        [0.4000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_independent = torch.tensor(X_train.values, dtype=torch.float)\n",
    "t_independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a616406-f6b2-490e-8d43-4a3c5e297b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
       "        1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
       "        0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "        0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
       "        1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
       "        0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
       "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
       "        1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1.,\n",
       "        0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
       "        0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0.,\n",
       "        0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0.,\n",
       "        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "        1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1.,\n",
       "        1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
       "        1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
       "        0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
       "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,\n",
       "        1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
       "        1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
       "        0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
       "        1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1.,\n",
       "        0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
       "        1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0.,\n",
       "        0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 1., 0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_dependent = torch.tensor(y_train.values, dtype=torch.float)\n",
    "t_dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37c9b42e-2eb3-4ad8-8790-e22ea61ead66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.1823, 2.8894, 0.8938, 2.6410, 1.5032], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = calculate_predictions(t_independent, weights)\n",
    "preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "104fee8a-2978-4f87-863a-9c1835540da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([891])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ed1238e-e65d-4155-8a90-18d018449a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([891])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds-t_dependent).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7fae27ae-9256-45e1-9d18-6dc5ded576c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0370, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = calculate_loss(preds, t_dependent)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc6c748-34ad-4700-a9ce-f6c186cfba77",
   "metadata": {},
   "source": [
    "### 2.3 Gradient descent step\n",
    "Calculate an epoch of gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2df871a-fe9a-4e1b-ad71-378f41c65a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 5e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22c71c3f-82a1-416c-afc1-3ff1b0862709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2009,  0.0197, -0.0083,  0.3054,  0.1181, -0.3794,  0.3723,  0.3662,\n",
       "          0.2323, -0.0597,  0.0644, -0.2248, -0.4564,  0.2257,  0.4999, -0.4412,\n",
       "         -0.0720, -0.2849,  0.2854]], requires_grad=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = initialise_weights(num_layers, num_features)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cce86ec0-189b-46dd-b0eb-5ef65c240046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0689, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0371)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the loss using the current weights\n",
    "preds = calculate_predictions(t_independent, weights)\n",
    "loss = calculate_loss(preds, t_dependent)\n",
    "print(loss)\n",
    "\n",
    "# Calculate the gradients\n",
    "loss.backward()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Take a gradient descent step\n",
    "    weights.subtract_(weights.grad * LEARNING_RATE)\n",
    "\n",
    "    # Reset gradients ready for the next step. Otherwise pytorch adds gradients on the next epoch.\n",
    "    weights.grad.zero_()\n",
    "\n",
    "    preds = calculate_predictions(t_independent, weights)\n",
    "    loss = calculate_loss(preds, t_dependent)\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8a8dee-cd85-48c7-b886-4f5ba3977683",
   "metadata": {},
   "source": [
    "The loss reduced as we hoped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd567b53-f220-4ae0-b5bf-30978436f36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_epoch(weights, t_independent, t_dependent, loss=None):\n",
    "    \"\"\"Run one epoch and return the weights and loss\"\"\"\n",
    "    \n",
    "    if loss is None:\n",
    "        # Use the loss from the previous epoch if passed in, otherwise calculate the loss using the current weights\n",
    "        preds = calculate_predictions(t_independent, weights)\n",
    "        loss = calculate_loss(preds, t_dependent)\n",
    "\n",
    "    # Calculate the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Take a gradient descent step\n",
    "        weights.subtract_(weights.grad * LEARNING_RATE)\n",
    "\n",
    "        # Reset gradients ready for the next step. Otherwise pytorch adds gradients on the next epoch.\n",
    "        weights.grad.zero_()\n",
    "\n",
    "    preds = calculate_predictions(t_independent, weights)\n",
    "    loss = calculate_loss(preds, t_dependent)\n",
    "\n",
    "    return weights, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2ec45af-dbe6-43d6-b821-527940c99b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2225, -0.2552, -0.0402, -0.3125, -0.3008, -0.2943,  0.3436, -0.4569,\n",
       "          0.2370, -0.2990, -0.1736,  0.2465,  0.3021, -0.0868,  0.4510,  0.3277,\n",
       "          0.3800, -0.0745, -0.1727]], requires_grad=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = initialise_weights(num_layers, num_features)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4564fca-c70a-4b4c-951c-60e6180b361b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0088685750961304\n"
     ]
    }
   ],
   "source": [
    "weights, loss = calculate_epoch(weights, t_independent, t_dependent, loss=None)\n",
    "print(float(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf0c0f89-201a-4382-97bc-ebde88b679b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9469995498657227\n"
     ]
    }
   ],
   "source": [
    "weights, loss = calculate_epoch(weights, t_independent, t_dependent, loss=loss)\n",
    "print(float(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dbaedfc6-d314-4162-83c0-7098c3690461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9004923701286316\n"
     ]
    }
   ],
   "source": [
    "weights, loss = calculate_epoch(weights, t_independent, t_dependent, loss=loss)\n",
    "print(float(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "185d9042-a8da-4f19-aea3-84c05f467f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8665304780006409\n"
     ]
    }
   ],
   "source": [
    "weights, loss = calculate_epoch(weights, t_independent, t_dependent, loss=loss)\n",
    "print(float(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ab1767d-cf2d-4c30-9b64-a7ef5cf9b638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8376653790473938\n"
     ]
    }
   ],
   "source": [
    "weights, loss = calculate_epoch(weights, t_independent, t_dependent, loss=loss)\n",
    "print(float(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938e1c0d-72f9-4008-9a1a-3e6beafe8944",
   "metadata": {},
   "source": [
    "### 2.4. Loop through multiple epochs\n",
    "Run multiple epochs of gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fcac991b-2ee1-43b8-8f14-a74fc682f2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84a043d2-8a61-423f-b075-08d5fc4e20d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9272493720054626\n",
      "0.9168375730514526\n",
      "0.906815230846405\n",
      "0.8972134590148926\n",
      "0.8881422877311707\n",
      "0.8793549537658691\n",
      "0.8708175420761108\n",
      "0.8626936674118042\n",
      "0.8548486232757568\n",
      "0.847531795501709\n",
      "0.8406753540039062\n",
      "0.8341706991195679\n",
      "0.8279553651809692\n",
      "0.8219183087348938\n",
      "0.8159963488578796\n",
      "0.8102097511291504\n",
      "0.804700493812561\n",
      "0.7993839979171753\n",
      "0.7942628264427185\n",
      "0.7892581820487976\n"
     ]
    }
   ],
   "source": [
    "weights = initialise_weights(num_layers, num_features)\n",
    "loss = None\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    weights, loss = calculate_epoch(weights, t_independent, t_dependent, loss=loss)\n",
    "    print(float(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ce1c277-2770-4f7f-bd37-22125e8f46a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear_model(t_independent, t_dependent, num_layers, num_epochs):\n",
    "    num_features = t_independent.shape[1]\n",
    "    weights = initialise_weights(num_layers, num_features)\n",
    "    loss = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        weights, loss = calculate_epoch(weights, t_independent, t_dependent, loss=loss)\n",
    "        if epoch % 10 == 0: print(epoch, float(loss))\n",
    "\n",
    "    return weights, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d278fd0-c8ca-48ba-85ea-e123c3ed140d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.2284592390060425\n",
      "10 0.5932685732841492\n",
      "20 0.4637145400047302\n",
      "30 0.45600515604019165\n",
      "40 0.45087799429893494\n",
      "50 0.44623124599456787\n",
      "60 0.4419229030609131\n",
      "70 0.4378982484340668\n",
      "80 0.43414369225502014\n",
      "90 0.430573970079422\n",
      "100 0.42713913321495056\n"
     ]
    }
   ],
   "source": [
    "weights, loss = train_linear_model(t_independent, t_dependent, num_layers=1, num_epochs=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "75d37ca2-1e95-46e7-bd5f-61921f3a39f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AgeNorm': tensor(0.3430),\n",
       " 'SibSp': tensor(-0.0613),\n",
       " 'Parch': tensor(-0.0990),\n",
       " 'Family': tensor(-0.0413),\n",
       " 'Alone': tensor(-0.4125),\n",
       " 'LogFare': tensor(0.0958),\n",
       " 'TicketFreq': tensor(0.0947),\n",
       " 'Pclass_2': tensor(-0.2630),\n",
       " 'Pclass_3': tensor(-0.3663),\n",
       " 'Sex_male': tensor(-0.4655),\n",
       " 'Embarked_Q': tensor(-0.2820),\n",
       " 'Embarked_S': tensor(0.4286),\n",
       " 'Deck_DE': tensor(-0.0938),\n",
       " 'Deck_FG': tensor(0.1596),\n",
       " 'Deck_Other': tensor(-0.1830),\n",
       " 'Title_Miss': tensor(0.2965),\n",
       " 'Title_Mr': tensor(0.4060),\n",
       " 'Title_Mrs': tensor(0.1030),\n",
       " 'Title_Other': tensor(-0.4593)}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(X_train.columns, *weights.requires_grad_(False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d690d43-3048-4a82-96e0-12d044d4633f",
   "metadata": {},
   "source": [
    "### 2.5. Measure accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7783232b-02c2-4a1f-971e-d7bb34c8ebca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(predictions, actuals):\n",
    "    return (predictions == actuals).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d757c69c-203d-4858-8d3a-00ceb8c3896e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6823793490460157"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_prob = calculate_predictions(t_independent, weights)\n",
    "predictions_classifications = predictions_prob > 0.5\n",
    "predictions_classifications = pd.Series(predictions_classifications.squeeze()).astype(int)\n",
    "\n",
    "calculate_accuracy(predictions_classifications, y_train.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "981a25ad-1c7d-421b-9347-6ad2ae71b084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.246126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.451054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.294903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.007012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.197942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.570054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.501532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  891.000000\n",
       "mean     0.246126\n",
       "std      0.451054\n",
       "min     -1.294903\n",
       "25%     -0.007012\n",
       "50%      0.197942\n",
       "75%      0.570054\n",
       "max      1.501532"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(predictions_prob).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3801c060-f566-42f3-9300-965b88f698c0",
   "metadata": {},
   "source": [
    "### 2.6. Add a sigmoid\n",
    "The output layer of a binary classifier should be bounded between 0 and 1.\n",
    "A sigmoid function handles this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f4ccc76d-d105-4e13-b5c9-319a1429cb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_predictions(features, weights):\n",
    "    \"\"\"Linear model to calculate predictions.\"\"\"\n",
    "    return torch.sigmoid(features @ weights.T).squeeze()\n",
    "    # return (features @ weights.T).squeeze()\n",
    "    # return torch.clamp(features @ weights.T, 0, 1).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5790054d-26ea-4904-bb8e-6b22da23e3b6",
   "metadata": {},
   "source": [
    "### 2.7 Train the model on a training set and compare validation set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "754c6476-58cf-4791-a5e7-6b6e6b189239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "153fc61b-2082-4c09-934f-ecb1b6d7b481",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_pct=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "296d3800-56f5-4f0f-810e-3704cec1d540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_set_split(data, validation_pct):\n",
    "    \"\"\"Given a collection of input data, return the indexes of the training and validation sets.\"\"\"\n",
    "    num_observations = data.shape[0]\n",
    "    validation_size = int(num_observations * validation_pct)\n",
    "    validation_idxs = sorted(random.sample(range(num_observations), validation_size))\n",
    "    training_idxs = list(set(range(num_observations)).difference(set(validation_idxs)))\n",
    "    return training_idxs, validation_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b672908a-de46-4887-8ada-7586c975104b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_idxs, validation_idxs = validation_set_split(t_independent, validation_pct=validation_pct)\n",
    "\n",
    "def train_linear_model(t_independent, t_dependent, num_layers, num_epochs):\n",
    "    # Split training/validation data\n",
    "    X_train = t_independent[training_idxs]\n",
    "    y_train = t_dependent[training_idxs]\n",
    "    X_validation = t_independent[validation_idxs]\n",
    "    y_validation = t_dependent[validation_idxs]\n",
    "\n",
    "    # Initialise weights\n",
    "    num_features = t_independent.shape[1]\n",
    "    weights = initialise_weights(num_layers, num_features)\n",
    "    loss = None\n",
    "\n",
    "    # Gradient descent\n",
    "    for epoch in range(num_epochs):\n",
    "        weights, loss = calculate_epoch(weights, X_train, y_train, loss=loss)\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            training_predictions = calculate_predictions(X_train, weights)\n",
    "            training_loss = calculate_loss(training_predictions, y_train)\n",
    "\n",
    "            validation_predictions = calculate_predictions(X_validation, weights)\n",
    "            validation_loss = calculate_loss(validation_predictions, y_validation)\n",
    "            print(epoch, float(training_loss), float(validation_loss))\n",
    "\n",
    "    return weights, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1e72dd31-0887-4e77-8785-cb77dafd5eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5023815631866455 0.48137643933296204\n",
      "10 0.4803462028503418 0.4576272964477539\n",
      "20 0.45871680974960327 0.4345540702342987\n",
      "30 0.43934422731399536 0.41457486152648926\n",
      "40 0.42293399572372437 0.39863744378089905\n",
      "50 0.4091772437095642 0.3863670229911804\n",
      "60 0.39735060930252075 0.3768177628517151\n",
      "70 0.38685426115989685 0.36903780698776245\n",
      "80 0.37758153676986694 0.36243802309036255\n",
      "90 0.36982017755508423 0.3569122552871704\n",
      "100 0.36362501978874207 0.35240206122398376\n",
      "110 0.358633816242218 0.3485826253890991\n",
      "120 0.3543953001499176 0.3450676500797272\n",
      "130 0.3505760729312897 0.34159815311431885\n",
      "140 0.34697502851486206 0.33805081248283386\n",
      "150 0.3434840440750122 0.33439019322395325\n",
      "160 0.3400515615940094 0.33062809705734253\n",
      "170 0.3366592526435852 0.3267989754676819\n",
      "180 0.3333069086074829 0.322945773601532\n",
      "190 0.33000338077545166 0.31911081075668335\n",
      "200 0.32676100730895996 0.31533166766166687\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.05\n",
    "weights, loss = train_linear_model(t_independent, t_dependent, num_layers=1, num_epochs=201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9a9d07aa-ef16-4687-b546-bccbd91cfc32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.268347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.214410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.014413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.093924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.147523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.420582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.820426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  178.000000\n",
       "mean     0.268347\n",
       "std      0.214410\n",
       "min      0.014413\n",
       "25%      0.093924\n",
       "50%      0.147523\n",
       "75%      0.420582\n",
       "max      0.820426"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(calculate_predictions(t_independent[validation_idxs], weights).detach().numpy()).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "173929b7-19e0-4826-b330-130b8e48a2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_predicted_classifications(predictions_prob):\n",
    "    predictions_classifications = predictions_prob > 0.5\n",
    "    return pd.Series(predictions_classifications.squeeze()).astype(int)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "405713ee-a4f4-434f-9f81-cfb5e08ad762",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7359550561797753"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_prob = calculate_predictions(t_independent[validation_idxs], weights)\n",
    "predictions_classifications = calculate_predicted_classifications(predictions_prob)\n",
    "\n",
    "calculate_accuracy(predictions_classifications, y_train[validation_idxs].reset_index(drop=True).astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b716703a-9c2f-4279-816e-b98fce1de87c",
   "metadata": {},
   "source": [
    "### 2.8. Submit to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d143af00-9abd-4abf-997c-7df90b825696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AgeNorm</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Family</th>\n",
       "      <th>Alone</th>\n",
       "      <th>LogFare</th>\n",
       "      <th>TicketFreq</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Deck_DE</th>\n",
       "      <th>Deck_FG</th>\n",
       "      <th>Deck_Other</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.453947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.178064</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.618421</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.369075</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.355263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.268252</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.289474</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.586824</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>0.398324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.202765</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>0.513158</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.699571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>0.506579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.110213</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>0.398324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.202765</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>0.398324</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.150952</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AgeNorm  SibSp  Parch  Family  Alone   LogFare  TicketFreq  Pclass_2  \\\n",
       "0    0.453947    0.0    0.0     0.0    1.0  2.178064         1.0       0.0   \n",
       "1    0.618421    1.0    0.0     1.0    0.0  2.079442         1.0       0.0   \n",
       "2    0.815789    0.0    0.0     0.0    1.0  2.369075         1.0       1.0   \n",
       "3    0.355263    0.0    0.0     0.0    1.0  2.268252         1.0       0.0   \n",
       "4    0.289474    1.0    1.0     2.0    0.0  2.586824         1.0       0.0   \n",
       "..        ...    ...    ...     ...    ...       ...         ...       ...   \n",
       "413  0.398324    0.0    0.0     0.0    1.0  2.202765         1.0       0.0   \n",
       "414  0.513158    0.0    0.0     0.0    1.0  4.699571         1.0       0.0   \n",
       "415  0.506579    0.0    0.0     0.0    1.0  2.110213         1.0       0.0   \n",
       "416  0.398324    0.0    0.0     0.0    1.0  2.202765         1.0       0.0   \n",
       "417  0.398324    1.0    1.0     2.0    0.0  3.150952         1.0       0.0   \n",
       "\n",
       "     Pclass_3  Sex_male  Embarked_Q  Embarked_S  Deck_DE  Deck_FG  Deck_Other  \\\n",
       "0         1.0       1.0         1.0         0.0      0.0      0.0         0.0   \n",
       "1         1.0       0.0         0.0         1.0      0.0      0.0         0.0   \n",
       "2         0.0       1.0         1.0         0.0      0.0      0.0         0.0   \n",
       "3         1.0       1.0         0.0         1.0      0.0      0.0         0.0   \n",
       "4         1.0       0.0         0.0         1.0      0.0      0.0         0.0   \n",
       "..        ...       ...         ...         ...      ...      ...         ...   \n",
       "413       1.0       1.0         0.0         1.0      0.0      0.0         0.0   \n",
       "414       0.0       0.0         0.0         0.0      0.0      0.0         0.0   \n",
       "415       1.0       1.0         0.0         1.0      0.0      0.0         0.0   \n",
       "416       1.0       1.0         0.0         1.0      0.0      0.0         0.0   \n",
       "417       1.0       1.0         0.0         0.0      0.0      0.0         0.0   \n",
       "\n",
       "     Title_Miss  Title_Mr  Title_Mrs  Title_Other  \n",
       "0           0.0       1.0        0.0          0.0  \n",
       "1           0.0       0.0        1.0          0.0  \n",
       "2           0.0       1.0        0.0          0.0  \n",
       "3           0.0       1.0        0.0          0.0  \n",
       "4           0.0       0.0        1.0          0.0  \n",
       "..          ...       ...        ...          ...  \n",
       "413         0.0       1.0        0.0          0.0  \n",
       "414         0.0       0.0        0.0          1.0  \n",
       "415         0.0       1.0        0.0          0.0  \n",
       "416         0.0       1.0        0.0          0.0  \n",
       "417         0.0       0.0        0.0          0.0  \n",
       "\n",
       "[418 rows x 19 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feature_df = calculate_features(test_df)\n",
    "test_feature_df['Deck_Other'] = 0.\n",
    "test_feature_df = test_feature_df[X_train.columns]\n",
    "test_feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8c0dfac5-aba8-4d72-b5ba-03de53b4116c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor = torch.tensor(test_feature_df.values, dtype=torch.float)\n",
    "test_predictions_prob = calculate_predictions(test_tensor, weights)\n",
    "test_predictions_classifications = calculate_predicted_classifications(test_predictions_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9231e151-35bc-4b42-b76a-f12f57133368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions_classifications.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4927d037-d120-4097-8105-e400e9d9eb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_903119/2927466126.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  output_df['Survived'] = test_predictions_classifications\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = test_df[['PassengerId']]\n",
    "output_df['Survived'] = test_predictions_classifications\n",
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "41a5fd04-8b70-46ca-9c54-cd0d51164402",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv('linear_model_output_sigmoid2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "05d09953-dfb5-4d32-a194-1a5506a9e61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived\n",
       "0    320\n",
       "1     98\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df['Survived'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd20e0b-c210-4b34-85fe-b5762aa52fc3",
   "metadata": {},
   "source": [
    "## 3. Train a neural network from scratch\n",
    "Repeat the previous process but with multiple hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6ab28a-5aa9-4d18-9ac7-e697fcaec3b6",
   "metadata": {},
   "source": [
    "### 3.1. Initialise weights\n",
    "We will now have weights per layer of the NN, where the size of each depends on the size of the hidder layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "76cc0665-e5d8-47a4-b92a-6ae992e90ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = X_train.shape[1]\n",
    "num_hidden_1 = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7b32d043-6732-43eb-b8a1-e1ee8d8a3105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_weights_nn(num_features, num_hidden_1):\n",
    "    # Divide by num_hidden so the magnitudes are comparable to the linear model when they're summed at the end\n",
    "    layer_1 = (torch.rand([num_features, num_hidden_1]) - 0.5) / num_hidden_1\n",
    "    layer_1.requires_grad_()\n",
    "    \n",
    "    # The 0.3 magic constant is a heuristic value to make the model train better\n",
    "    layer_2 = torch.rand([num_hidden_1, 1]) - 0.3\n",
    "    layer_2.requires_grad_()\n",
    "    \n",
    "    const = torch.rand(1)[0]\n",
    "    const.requires_grad_()\n",
    "    \n",
    "    return layer_1, layer_2, const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "76d91223-c426-4cb3-b3e7-f1536964afed",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = initialise_weights_nn(num_features, num_hidden_1)\n",
    "layer_1, layer_2, const = weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60404b07-4450-4932-a14a-0be44b1240dc",
   "metadata": {},
   "source": [
    "### 3.2. Implement the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f64da0d3-d39f-4a43-9c8a-46d7e33f0e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a99293c0-ffd6-4545-a43f-61d256a03ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_predictions_nn(features, weights):\n",
    "    layer_1, layer_2, const = weights\n",
    "    res = F.relu(features @ layer_1)\n",
    "    res = res @ layer_2 + const\n",
    "    # return torch.sigmoid(res)\n",
    "    return torch.clamp(res, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "270b04b8-bfea-41d8-85c0-4c9604874477",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7752],\n",
       "        [0.7802],\n",
       "        [0.7261],\n",
       "        [0.8186],\n",
       "        [0.7652],\n",
       "        [0.7065],\n",
       "        [0.7683],\n",
       "        [0.8691],\n",
       "        [0.7491],\n",
       "        [0.7442],\n",
       "        [0.7893],\n",
       "        [0.7513],\n",
       "        [0.7620],\n",
       "        [0.9077],\n",
       "        [0.7247],\n",
       "        [0.7505],\n",
       "        [0.8967],\n",
       "        [0.7385],\n",
       "        [0.8048],\n",
       "        [0.7021],\n",
       "        [0.7586],\n",
       "        [0.7039],\n",
       "        [0.6708],\n",
       "        [0.7881],\n",
       "        [0.8950],\n",
       "        [0.9357],\n",
       "        [0.7134],\n",
       "        [0.9482],\n",
       "        [0.6714],\n",
       "        [0.7636],\n",
       "        [0.7131],\n",
       "        [0.8061],\n",
       "        [0.6710],\n",
       "        [0.7356],\n",
       "        [0.7788],\n",
       "        [0.8111],\n",
       "        [0.7134],\n",
       "        [0.7622],\n",
       "        [0.8019],\n",
       "        [0.7336],\n",
       "        [0.7882],\n",
       "        [0.7703],\n",
       "        [0.7150],\n",
       "        [0.7741],\n",
       "        [0.6706],\n",
       "        [0.7640],\n",
       "        [0.7408],\n",
       "        [0.6710],\n",
       "        [0.7815],\n",
       "        [0.7998],\n",
       "        [0.9509],\n",
       "        [0.7613],\n",
       "        [0.7747],\n",
       "        [0.7798],\n",
       "        [0.7371],\n",
       "        [0.7882],\n",
       "        [0.6983],\n",
       "        [0.7132],\n",
       "        [0.7870],\n",
       "        [1.0000],\n",
       "        [0.7116],\n",
       "        [0.7871],\n",
       "        [0.8264],\n",
       "        [0.8952],\n",
       "        [0.7252],\n",
       "        [0.7196],\n",
       "        [0.7419],\n",
       "        [0.7623],\n",
       "        [1.0000],\n",
       "        [0.8098],\n",
       "        [0.7320],\n",
       "        [1.0000],\n",
       "        [0.8237],\n",
       "        [0.7437],\n",
       "        [0.9258],\n",
       "        [0.7730],\n",
       "        [0.7636],\n",
       "        [0.7640],\n",
       "        [0.7340],\n",
       "        [0.7400],\n",
       "        [0.7655],\n",
       "        [0.7681],\n",
       "        [0.6711],\n",
       "        [0.7971],\n",
       "        [0.6979],\n",
       "        [0.8853],\n",
       "        [0.8390],\n",
       "        [0.7640],\n",
       "        [0.9403],\n",
       "        [0.7626],\n",
       "        [0.7638],\n",
       "        [0.7613],\n",
       "        [0.7863],\n",
       "        [0.8135],\n",
       "        [0.7684],\n",
       "        [0.7640],\n",
       "        [0.7379],\n",
       "        [0.7027],\n",
       "        [0.7411],\n",
       "        [0.7733],\n",
       "        [0.7262],\n",
       "        [0.7636],\n",
       "        [0.7607],\n",
       "        [0.7661],\n",
       "        [0.8072],\n",
       "        [0.7632],\n",
       "        [0.7246],\n",
       "        [0.7633],\n",
       "        [0.7656],\n",
       "        [0.7451],\n",
       "        [0.7982],\n",
       "        [0.7375],\n",
       "        [0.7623],\n",
       "        [0.7547],\n",
       "        [0.7074],\n",
       "        [0.7617],\n",
       "        [0.7149],\n",
       "        [0.7684],\n",
       "        [0.7839],\n",
       "        [1.0000],\n",
       "        [0.8872],\n",
       "        [0.7640],\n",
       "        [0.7423],\n",
       "        [0.6773],\n",
       "        [0.7625],\n",
       "        [0.7068],\n",
       "        [0.7049],\n",
       "        [0.7605],\n",
       "        [0.7539],\n",
       "        [0.7651],\n",
       "        [0.7158],\n",
       "        [0.7593],\n",
       "        [0.8001],\n",
       "        [0.7798],\n",
       "        [0.7380],\n",
       "        [0.6861],\n",
       "        [0.7141],\n",
       "        [0.8115],\n",
       "        [0.7659],\n",
       "        [0.7628],\n",
       "        [0.7132],\n",
       "        [0.7251],\n",
       "        [0.7971],\n",
       "        [0.6999],\n",
       "        [0.7335],\n",
       "        [0.7950],\n",
       "        [0.7627],\n",
       "        [0.8654],\n",
       "        [0.7702],\n",
       "        [0.7244],\n",
       "        [0.7249],\n",
       "        [0.8239],\n",
       "        [0.7695],\n",
       "        [0.7621],\n",
       "        [0.7622],\n",
       "        [0.7360],\n",
       "        [0.6699],\n",
       "        [0.7640],\n",
       "        [0.7655],\n",
       "        [1.0000],\n",
       "        [0.7712],\n",
       "        [0.7489],\n",
       "        [0.7625],\n",
       "        [0.7637],\n",
       "        [0.9516],\n",
       "        [0.7432],\n",
       "        [0.7553],\n",
       "        [0.8719],\n",
       "        [0.7782],\n",
       "        [0.9250],\n",
       "        [0.7881],\n",
       "        [0.8963],\n",
       "        [0.7666],\n",
       "        [0.7617],\n",
       "        [0.7324],\n",
       "        [0.7804],\n",
       "        [0.8655],\n",
       "        [0.7136],\n",
       "        [0.7385],\n",
       "        [0.7969],\n",
       "        [1.0000],\n",
       "        [0.6871],\n",
       "        [0.9783],\n",
       "        [0.8268],\n",
       "        [0.7666],\n",
       "        [0.7991],\n",
       "        [0.7311],\n",
       "        [0.7798],\n",
       "        [0.7485],\n",
       "        [0.7651],\n",
       "        [0.7423],\n",
       "        [0.7374],\n",
       "        [0.7487],\n",
       "        [0.7756],\n",
       "        [0.7317],\n",
       "        [0.7693],\n",
       "        [0.7049],\n",
       "        [0.7556],\n",
       "        [0.6710],\n",
       "        [0.7049],\n",
       "        [0.7679],\n",
       "        [1.0000],\n",
       "        [0.7612],\n",
       "        [0.7172],\n",
       "        [0.7617],\n",
       "        [0.7277],\n",
       "        [0.7961],\n",
       "        [0.7357],\n",
       "        [0.6700],\n",
       "        [0.7305],\n",
       "        [0.7602],\n",
       "        [0.7208],\n",
       "        [0.7603],\n",
       "        [0.7385],\n",
       "        [0.7272],\n",
       "        [0.7866],\n",
       "        [0.7262],\n",
       "        [0.7743],\n",
       "        [0.7130],\n",
       "        [0.7318],\n",
       "        [0.7615],\n",
       "        [0.7382],\n",
       "        [0.7687],\n",
       "        [0.7636],\n",
       "        [0.8284],\n",
       "        [0.7666],\n",
       "        [0.7308],\n",
       "        [0.7599],\n",
       "        [0.7373],\n",
       "        [0.8923],\n",
       "        [0.8328],\n",
       "        [0.7632],\n",
       "        [0.7426],\n",
       "        [0.9962],\n",
       "        [0.7313],\n",
       "        [0.7251],\n",
       "        [0.7758],\n",
       "        [0.7481],\n",
       "        [0.7308],\n",
       "        [0.7370],\n",
       "        [0.7367],\n",
       "        [0.7187],\n",
       "        [0.7317],\n",
       "        [0.7599],\n",
       "        [0.7135],\n",
       "        [0.7850],\n",
       "        [0.7254],\n",
       "        [0.7454],\n",
       "        [0.7775],\n",
       "        [0.7620],\n",
       "        [0.7621],\n",
       "        [0.7917],\n",
       "        [0.7808],\n",
       "        [0.7964],\n",
       "        [0.7736],\n",
       "        [0.7264],\n",
       "        [0.7632],\n",
       "        [0.7939],\n",
       "        [0.8103],\n",
       "        [0.7460],\n",
       "        [0.7049],\n",
       "        [0.9796],\n",
       "        [0.7904],\n",
       "        [0.7003],\n",
       "        [0.6710],\n",
       "        [0.7324],\n",
       "        [0.9815],\n",
       "        [0.7774],\n",
       "        [0.8245],\n",
       "        [0.8077],\n",
       "        [0.7808],\n",
       "        [0.7946],\n",
       "        [0.7370],\n",
       "        [0.7123],\n",
       "        [0.6710],\n",
       "        [0.7909],\n",
       "        [0.7273],\n",
       "        [0.7113],\n",
       "        [0.8957],\n",
       "        [0.8060],\n",
       "        [0.7136],\n",
       "        [0.7631],\n",
       "        [0.7662],\n",
       "        [0.7619],\n",
       "        [0.7783],\n",
       "        [0.7175],\n",
       "        [0.7682],\n",
       "        [0.7618],\n",
       "        [0.7397],\n",
       "        [0.6704],\n",
       "        [0.7850],\n",
       "        [0.7896],\n",
       "        [0.6472],\n",
       "        [0.7289],\n",
       "        [0.7623],\n",
       "        [0.7252],\n",
       "        [0.7120],\n",
       "        [0.8524],\n",
       "        [0.7833],\n",
       "        [0.7906],\n",
       "        [0.6710],\n",
       "        [0.7798],\n",
       "        [0.7931],\n",
       "        [0.6287],\n",
       "        [0.7640],\n",
       "        [0.8264],\n",
       "        [0.8086],\n",
       "        [0.7950],\n",
       "        [0.7364],\n",
       "        [0.7137],\n",
       "        [0.7464],\n",
       "        [0.8553],\n",
       "        [0.7929],\n",
       "        [0.7632],\n",
       "        [0.7881],\n",
       "        [0.7258],\n",
       "        [0.7761],\n",
       "        [0.7283],\n",
       "        [0.7883],\n",
       "        [0.7714],\n",
       "        [0.7603],\n",
       "        [0.7630],\n",
       "        [0.6487],\n",
       "        [0.7886],\n",
       "        [1.0000],\n",
       "        [0.7781],\n",
       "        [0.7659],\n",
       "        [0.7163],\n",
       "        [0.8007],\n",
       "        [0.7309],\n",
       "        [0.7690],\n",
       "        [0.7821],\n",
       "        [0.8162],\n",
       "        [0.8219],\n",
       "        [0.8470],\n",
       "        [0.7636],\n",
       "        [0.8183],\n",
       "        [0.7392],\n",
       "        [0.7675],\n",
       "        [0.8009],\n",
       "        [0.7757],\n",
       "        [0.9402],\n",
       "        [0.7383],\n",
       "        [0.7380],\n",
       "        [0.7391],\n",
       "        [0.7180],\n",
       "        [0.7071],\n",
       "        [0.8014],\n",
       "        [0.7635],\n",
       "        [0.7681],\n",
       "        [0.7664],\n",
       "        [0.7877],\n",
       "        [0.7416],\n",
       "        [0.7992],\n",
       "        [0.7134],\n",
       "        [0.7679],\n",
       "        [0.7323],\n",
       "        [0.7068],\n",
       "        [0.6714],\n",
       "        [0.6714],\n",
       "        [0.8772],\n",
       "        [0.7316],\n",
       "        [0.7134],\n",
       "        [0.7629],\n",
       "        [0.7406],\n",
       "        [0.7622],\n",
       "        [0.7549],\n",
       "        [0.7021],\n",
       "        [0.6710],\n",
       "        [0.7422],\n",
       "        [0.7285],\n",
       "        [0.7724],\n",
       "        [0.7619],\n",
       "        [0.7835],\n",
       "        [0.8957],\n",
       "        [0.7878],\n",
       "        [0.7232],\n",
       "        [0.7685],\n",
       "        [0.7011],\n",
       "        [0.7609],\n",
       "        [0.8200],\n",
       "        [0.7124],\n",
       "        [0.7642],\n",
       "        [0.8179],\n",
       "        [0.7636],\n",
       "        [0.8236],\n",
       "        [1.0000],\n",
       "        [0.7065],\n",
       "        [0.7049],\n",
       "        [0.6586],\n",
       "        [0.8441],\n",
       "        [0.7613],\n",
       "        [0.8080],\n",
       "        [0.7869],\n",
       "        [0.7716],\n",
       "        [0.7616],\n",
       "        [0.7263],\n",
       "        [0.7601],\n",
       "        [0.7158],\n",
       "        [0.7412],\n",
       "        [0.7659],\n",
       "        [0.7631],\n",
       "        [0.7547],\n",
       "        [0.7958],\n",
       "        [0.7280],\n",
       "        [0.7687],\n",
       "        [0.7680],\n",
       "        [0.7560],\n",
       "        [0.7613],\n",
       "        [0.8923],\n",
       "        [0.7636],\n",
       "        [0.7028],\n",
       "        [0.7564],\n",
       "        [0.7113],\n",
       "        [0.7670],\n",
       "        [0.7608],\n",
       "        [0.7937],\n",
       "        [0.7331],\n",
       "        [0.7385],\n",
       "        [0.7565],\n",
       "        [0.7150],\n",
       "        [0.7028],\n",
       "        [0.7634],\n",
       "        [0.7998],\n",
       "        [0.7964],\n",
       "        [0.7621],\n",
       "        [0.7797],\n",
       "        [0.7293],\n",
       "        [0.7049],\n",
       "        [0.7442],\n",
       "        [0.7789],\n",
       "        [0.7981],\n",
       "        [0.7811],\n",
       "        [0.7588],\n",
       "        [0.7809],\n",
       "        [0.8471],\n",
       "        [0.8644],\n",
       "        [0.9119],\n",
       "        [0.8920],\n",
       "        [0.7319],\n",
       "        [0.7892],\n",
       "        [0.7668],\n",
       "        [0.7774],\n",
       "        [0.7102],\n",
       "        [0.7641],\n",
       "        [0.7623],\n",
       "        [0.7215],\n",
       "        [0.7792],\n",
       "        [0.8291],\n",
       "        [0.7712],\n",
       "        [0.8050],\n",
       "        [0.8059],\n",
       "        [0.7253],\n",
       "        [0.7835],\n",
       "        [0.7640],\n",
       "        [0.7149],\n",
       "        [0.7476],\n",
       "        [0.7863],\n",
       "        [0.7023],\n",
       "        [0.7049],\n",
       "        [0.7461],\n",
       "        [0.7650],\n",
       "        [0.7582],\n",
       "        [0.7403],\n",
       "        [0.7640],\n",
       "        [0.7636],\n",
       "        [0.7113],\n",
       "        [0.7804],\n",
       "        [0.7049],\n",
       "        [0.8291],\n",
       "        [0.7621],\n",
       "        [0.7673],\n",
       "        [0.8063],\n",
       "        [0.6592],\n",
       "        [0.7317],\n",
       "        [0.7973],\n",
       "        [0.7680],\n",
       "        [0.7755],\n",
       "        [0.7609],\n",
       "        [0.7296],\n",
       "        [1.0000],\n",
       "        [0.6735],\n",
       "        [0.7685],\n",
       "        [0.7689],\n",
       "        [0.7820],\n",
       "        [0.8923],\n",
       "        [0.8352],\n",
       "        [0.7315],\n",
       "        [0.7640],\n",
       "        [0.7629],\n",
       "        [0.8059],\n",
       "        [0.7600],\n",
       "        [0.7848],\n",
       "        [0.7496],\n",
       "        [0.7622],\n",
       "        [0.7314],\n",
       "        [0.7491],\n",
       "        [0.7818],\n",
       "        [0.8565],\n",
       "        [0.7620],\n",
       "        [0.7637],\n",
       "        [0.6703],\n",
       "        [0.6706],\n",
       "        [0.7325],\n",
       "        [0.7910],\n",
       "        [0.7873],\n",
       "        [0.7555],\n",
       "        [0.7790],\n",
       "        [0.7935],\n",
       "        [0.9246],\n",
       "        [0.7047],\n",
       "        [0.7640],\n",
       "        [0.7446],\n",
       "        [0.7766],\n",
       "        [0.7613],\n",
       "        [0.7541],\n",
       "        [0.7423],\n",
       "        [0.7338],\n",
       "        [0.7805],\n",
       "        [0.7642],\n",
       "        [0.7910],\n",
       "        [0.7618],\n",
       "        [0.7134],\n",
       "        [0.7438],\n",
       "        [0.7134],\n",
       "        [0.7076],\n",
       "        [0.7023],\n",
       "        [0.8459],\n",
       "        [0.7659],\n",
       "        [0.8332],\n",
       "        [0.7678],\n",
       "        [0.7134],\n",
       "        [0.7413],\n",
       "        [0.7199],\n",
       "        [0.7289],\n",
       "        [0.7480],\n",
       "        [0.7660],\n",
       "        [0.7546],\n",
       "        [0.7806],\n",
       "        [0.7226],\n",
       "        [0.7678],\n",
       "        [1.0000],\n",
       "        [1.0000],\n",
       "        [0.7735],\n",
       "        [0.7895],\n",
       "        [0.7802],\n",
       "        [0.7756],\n",
       "        [0.6848],\n",
       "        [0.7979],\n",
       "        [0.7688],\n",
       "        [0.7839],\n",
       "        [0.7604],\n",
       "        [0.7051],\n",
       "        [0.7116],\n",
       "        [0.7252],\n",
       "        [0.7808],\n",
       "        [0.7426],\n",
       "        [0.8204],\n",
       "        [0.7964],\n",
       "        [0.8042],\n",
       "        [0.7049],\n",
       "        [0.7661],\n",
       "        [0.7395],\n",
       "        [0.7640],\n",
       "        [0.7269],\n",
       "        [0.8311],\n",
       "        [0.7613],\n",
       "        [0.8216],\n",
       "        [0.7134],\n",
       "        [0.7641],\n",
       "        [0.7352],\n",
       "        [0.8424],\n",
       "        [0.7447],\n",
       "        [0.6710],\n",
       "        [0.7615],\n",
       "        [0.7755],\n",
       "        [0.7062],\n",
       "        [0.7903],\n",
       "        [0.7419],\n",
       "        [0.7642],\n",
       "        [0.7703],\n",
       "        [0.8166],\n",
       "        [0.7610],\n",
       "        [0.7384],\n",
       "        [0.7168],\n",
       "        [0.7650],\n",
       "        [0.7447],\n",
       "        [0.7690],\n",
       "        [0.7623],\n",
       "        [0.7640],\n",
       "        [0.7631],\n",
       "        [0.7607],\n",
       "        [0.7661],\n",
       "        [0.7133],\n",
       "        [0.7755],\n",
       "        [0.8014],\n",
       "        [0.7435],\n",
       "        [0.7995],\n",
       "        [0.7134],\n",
       "        [0.7631],\n",
       "        [0.8491],\n",
       "        [0.7636],\n",
       "        [0.7938],\n",
       "        [0.7673],\n",
       "        [0.7245],\n",
       "        [0.7985],\n",
       "        [0.7637],\n",
       "        [0.7832],\n",
       "        [0.7816],\n",
       "        [0.8122],\n",
       "        [0.9079],\n",
       "        [0.7616],\n",
       "        [0.7187],\n",
       "        [0.7049],\n",
       "        [0.7652],\n",
       "        [0.8038],\n",
       "        [0.7869],\n",
       "        [0.7977],\n",
       "        [0.8386],\n",
       "        [0.7315],\n",
       "        [0.7520],\n",
       "        [0.7812],\n",
       "        [0.7545],\n",
       "        [0.7615],\n",
       "        [0.7788],\n",
       "        [0.7536],\n",
       "        [0.6574],\n",
       "        [0.7686],\n",
       "        [0.7627],\n",
       "        [0.7049],\n",
       "        [0.7856],\n",
       "        [0.7664],\n",
       "        [0.7147],\n",
       "        [0.6986],\n",
       "        [0.9397],\n",
       "        [0.7054],\n",
       "        [0.7642],\n",
       "        [0.7891],\n",
       "        [0.8489],\n",
       "        [0.7964],\n",
       "        [0.7613],\n",
       "        [0.7422],\n",
       "        [0.9408],\n",
       "        [0.9253],\n",
       "        [0.8291],\n",
       "        [0.7721],\n",
       "        [0.7613],\n",
       "        [0.7238],\n",
       "        [0.7628],\n",
       "        [0.7244],\n",
       "        [0.7636],\n",
       "        [0.7259],\n",
       "        [0.7635],\n",
       "        [0.6712],\n",
       "        [0.6667],\n",
       "        [0.8868],\n",
       "        [0.7636],\n",
       "        [0.7430],\n",
       "        [0.7378],\n",
       "        [0.7486],\n",
       "        [0.8523],\n",
       "        [0.7159],\n",
       "        [0.7448],\n",
       "        [0.7642],\n",
       "        [0.7777],\n",
       "        [0.8859],\n",
       "        [0.7380],\n",
       "        [0.7633],\n",
       "        [0.7671],\n",
       "        [0.8172],\n",
       "        [0.7941],\n",
       "        [0.8132],\n",
       "        [0.7360],\n",
       "        [0.7386],\n",
       "        [0.6735],\n",
       "        [0.7607],\n",
       "        [0.7627],\n",
       "        [0.7313],\n",
       "        [0.9611],\n",
       "        [0.8134],\n",
       "        [0.6722],\n",
       "        [0.7511],\n",
       "        [0.7660],\n",
       "        [1.0000],\n",
       "        [0.7929],\n",
       "        [0.7743],\n",
       "        [0.9818],\n",
       "        [0.7687],\n",
       "        [0.7608],\n",
       "        [0.8042],\n",
       "        [0.8135],\n",
       "        [0.6871],\n",
       "        [0.9253],\n",
       "        [0.7123],\n",
       "        [0.7680],\n",
       "        [0.7419],\n",
       "        [0.7673],\n",
       "        [0.6709],\n",
       "        [0.8146],\n",
       "        [0.7772],\n",
       "        [0.8361],\n",
       "        [0.7445],\n",
       "        [0.6960],\n",
       "        [0.7037],\n",
       "        [0.7778],\n",
       "        [0.7591],\n",
       "        [0.7445],\n",
       "        [0.7452],\n",
       "        [0.8273],\n",
       "        [0.7196],\n",
       "        [0.7261],\n",
       "        [0.7790],\n",
       "        [0.8114],\n",
       "        [0.7680],\n",
       "        [0.7390],\n",
       "        [0.7720],\n",
       "        [0.8197],\n",
       "        [0.6702],\n",
       "        [0.7177],\n",
       "        [0.7641],\n",
       "        [0.7439],\n",
       "        [0.7742],\n",
       "        [0.7389],\n",
       "        [0.7405],\n",
       "        [0.7779],\n",
       "        [0.7641],\n",
       "        [0.8736],\n",
       "        [0.6710],\n",
       "        [0.7748],\n",
       "        [0.7481],\n",
       "        [0.8207],\n",
       "        [0.7315],\n",
       "        [0.6735],\n",
       "        [0.7378],\n",
       "        [0.7378],\n",
       "        [0.7795],\n",
       "        [0.8487],\n",
       "        [0.8280],\n",
       "        [0.7636],\n",
       "        [0.7636],\n",
       "        [0.7483],\n",
       "        [0.8241],\n",
       "        [0.8550],\n",
       "        [0.7990],\n",
       "        [0.7640],\n",
       "        [0.8042],\n",
       "        [0.7964],\n",
       "        [0.7057],\n",
       "        [0.7804],\n",
       "        [0.7052],\n",
       "        [0.7732],\n",
       "        [0.7038],\n",
       "        [0.7686],\n",
       "        [0.7620],\n",
       "        [0.8256],\n",
       "        [0.7466],\n",
       "        [0.7630],\n",
       "        [0.7335],\n",
       "        [0.7650],\n",
       "        [0.7984],\n",
       "        [0.7766],\n",
       "        [0.7645],\n",
       "        [0.7111],\n",
       "        [0.8497],\n",
       "        [0.7605],\n",
       "        [0.8079],\n",
       "        [0.7227],\n",
       "        [0.6711],\n",
       "        [0.7570],\n",
       "        [0.7652],\n",
       "        [0.7674],\n",
       "        [0.7676],\n",
       "        [0.7051],\n",
       "        [0.7134],\n",
       "        [0.8655],\n",
       "        [0.7607],\n",
       "        [0.7235],\n",
       "        [0.7365],\n",
       "        [0.7049],\n",
       "        [0.8326],\n",
       "        [0.6757],\n",
       "        [0.8184],\n",
       "        [0.7482],\n",
       "        [0.8146],\n",
       "        [0.7605],\n",
       "        [0.7610],\n",
       "        [0.7238],\n",
       "        [0.8955],\n",
       "        [0.7987],\n",
       "        [0.7658],\n",
       "        [0.7049],\n",
       "        [0.7559],\n",
       "        [1.0000],\n",
       "        [0.7286],\n",
       "        [0.7625],\n",
       "        [0.7394],\n",
       "        [0.7274],\n",
       "        [0.7630],\n",
       "        [0.7135],\n",
       "        [0.8053],\n",
       "        [0.7371],\n",
       "        [0.7900],\n",
       "        [0.8193],\n",
       "        [0.6681],\n",
       "        [0.7608],\n",
       "        [0.7637],\n",
       "        [0.7001],\n",
       "        [0.7248],\n",
       "        [0.7394],\n",
       "        [0.7881],\n",
       "        [0.7627],\n",
       "        [0.7926],\n",
       "        [0.7323],\n",
       "        [1.0000],\n",
       "        [0.7642],\n",
       "        [0.6986],\n",
       "        [0.7258],\n",
       "        [0.7536],\n",
       "        [0.7632],\n",
       "        [0.8945],\n",
       "        [0.8299],\n",
       "        [0.7651],\n",
       "        [0.6888],\n",
       "        [0.7285],\n",
       "        [0.9515],\n",
       "        [0.7030],\n",
       "        [0.9253],\n",
       "        [0.6999],\n",
       "        [0.7049],\n",
       "        [0.8152],\n",
       "        [0.7444],\n",
       "        [0.7562],\n",
       "        [0.7134],\n",
       "        [0.7619],\n",
       "        [0.7626],\n",
       "        [0.7417],\n",
       "        [0.7643],\n",
       "        [0.7640],\n",
       "        [0.9258],\n",
       "        [0.7276],\n",
       "        [0.7616],\n",
       "        [0.7286],\n",
       "        [0.7226],\n",
       "        [0.7125],\n",
       "        [0.7637],\n",
       "        [0.7658],\n",
       "        [1.0000],\n",
       "        [0.7163],\n",
       "        [0.7410],\n",
       "        [0.7904],\n",
       "        [0.9692],\n",
       "        [0.7719],\n",
       "        [0.7409],\n",
       "        [0.7108],\n",
       "        [0.7781],\n",
       "        [0.7569],\n",
       "        [0.8478],\n",
       "        [0.7464],\n",
       "        [0.7534],\n",
       "        [0.7134],\n",
       "        [0.8181],\n",
       "        [0.7507],\n",
       "        [0.7568],\n",
       "        [1.0000],\n",
       "        [0.7379],\n",
       "        [0.7431],\n",
       "        [0.7090],\n",
       "        [0.7995],\n",
       "        [0.7682],\n",
       "        [0.7580],\n",
       "        [0.7627],\n",
       "        [0.7788],\n",
       "        [0.7284],\n",
       "        [0.7698],\n",
       "        [0.7386],\n",
       "        [0.6759],\n",
       "        [0.7678],\n",
       "        [0.7613],\n",
       "        [0.7636],\n",
       "        [0.7568],\n",
       "        [0.7437],\n",
       "        [0.7644],\n",
       "        [0.7336],\n",
       "        [0.7317],\n",
       "        [0.7605],\n",
       "        [0.8207],\n",
       "        [0.7220],\n",
       "        [0.7504],\n",
       "        [0.8091],\n",
       "        [0.7272],\n",
       "        [0.7055]], grad_fn=<ClampBackward1>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_predictions_nn(t_independent, (layer_1, layer_2, const))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6956f3bd-84bc-4464-b441-83e829c543c4",
   "metadata": {},
   "source": [
    "### 3.3. Reimplement gradient descent\n",
    "Only the weights.subtract part needs to change, as we now need to loop through the multiple layers. \n",
    "\n",
    "In the original notebook, this part of the function is encapsulated in an update_coeffs which can be overwritten.\n",
    "\n",
    "But I wanted to explicitly see the change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ef943591-3a02-4cb5-9155-b368b88383f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_epoch_nn(weights, t_independent, t_dependent, loss=None):\n",
    "    \"\"\"Run one epoch and return the weights and loss\"\"\"\n",
    "    if loss is None:\n",
    "        # Use the loss from the previous epoch if passed in, otherwise calculate the loss using the current weights\n",
    "        preds = calculate_predictions_nn(t_independent, weights)\n",
    "        loss = calculate_loss(preds, t_dependent)\n",
    "\n",
    "    # Calculate the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Take a gradient descent step\n",
    "        for layer in weights:  # This for loop is the only change compared to the previous calculate_epoch function\n",
    "            layer.sub_(layer.grad * LEARNING_RATE)\n",
    "            layer.grad.zero_()\n",
    "\n",
    "    preds = calculate_predictions_nn(t_independent, weights)\n",
    "    loss = calculate_loss(preds, t_dependent)\n",
    "\n",
    "    return weights, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc1fb5b-5db6-4153-9abf-581590697a71",
   "metadata": {},
   "source": [
    "### 3.4. Train the neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "68d648cb-2b09-425d-867a-a26c31d023a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_idxs, validation_idxs = validation_set_split(t_independent, validation_pct=validation_pct)\n",
    "\n",
    "def train_nn_model(t_independent, t_dependent, num_hidden_1, num_epochs):\n",
    "    # Split training/validation data\n",
    "    X_train = t_independent[training_idxs]\n",
    "    y_train = t_dependent[training_idxs]\n",
    "    X_validation = t_independent[validation_idxs]\n",
    "    y_validation = t_dependent[validation_idxs]\n",
    "\n",
    "    # Initialise weights\n",
    "    num_features = t_independent.shape[1]\n",
    "    weights = initialise_weights_nn(num_features, num_hidden_1)\n",
    "    loss = None\n",
    "\n",
    "    # Gradient descent\n",
    "    for epoch in range(num_epochs):\n",
    "        weights, loss = calculate_epoch_nn(weights, X_train, y_train, loss=loss)\n",
    "\n",
    "        # Periodically print loss\n",
    "        if epoch % 10 == 0:\n",
    "            training_predictions = calculate_predictions_nn(X_train, weights)\n",
    "            training_loss = calculate_loss(training_predictions, y_train)\n",
    "            validation_predictions = calculate_predictions_nn(X_validation, weights)\n",
    "            validation_loss = calculate_loss(validation_predictions, y_validation)\n",
    "            print(epoch, float(training_loss), float(validation_loss))\n",
    "\n",
    "    return weights, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fb14db9e-655c-4251-b00e-a23b8f08f4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.409184992313385 0.42848849296569824\n",
      "10 0.37873926758766174 0.4046975374221802\n",
      "20 0.3787175118923187 0.4046306014060974\n",
      "30 0.3786957263946533 0.404563307762146\n",
      "40 0.378683477640152 0.4045388400554657\n",
      "50 0.37868162989616394 0.40453559160232544\n",
      "60 0.37868162989616394 0.40453559160232544\n",
      "70 0.37868162989616394 0.40453559160232544\n",
      "80 0.37868162989616394 0.40453559160232544\n",
      "90 0.37868162989616394 0.40453559160232544\n",
      "100 0.37868162989616394 0.40453559160232544\n",
      "110 0.37868162989616394 0.40453559160232544\n",
      "120 0.37868162989616394 0.40453559160232544\n",
      "130 0.37868162989616394 0.40453559160232544\n",
      "140 0.37868162989616394 0.40453559160232544\n",
      "150 0.37868162989616394 0.40453559160232544\n",
      "160 0.37868162989616394 0.40453559160232544\n",
      "170 0.37868162989616394 0.40453559160232544\n",
      "180 0.37868162989616394 0.40453559160232544\n",
      "190 0.37868162989616394 0.40453559160232544\n",
      "200 0.37868162989616394 0.40453559160232544\n",
      "210 0.37868162989616394 0.40453559160232544\n",
      "220 0.37868162989616394 0.40453559160232544\n",
      "230 0.37868162989616394 0.40453559160232544\n",
      "240 0.37868162989616394 0.40453559160232544\n",
      "250 0.37868162989616394 0.40453559160232544\n",
      "260 0.37868162989616394 0.40453559160232544\n",
      "270 0.37868162989616394 0.40453559160232544\n",
      "280 0.37868162989616394 0.40453559160232544\n",
      "290 0.37868162989616394 0.40453559160232544\n",
      "300 0.37868162989616394 0.40453559160232544\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.5\n",
    "weights, loss = train_nn_model(t_independent, t_dependent, num_hidden_1, num_epochs=301)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcef164-1bb4-4547-bb0f-eddbce902a66",
   "metadata": {},
   "source": [
    "### 3.5. Use the model for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7dc3a0e0-311c-4c70-8eca-15330793e569",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5955056179775281"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_prob = calculate_predictions_nn(t_independent[validation_idxs], weights)\n",
    "predictions_classifications = calculate_predicted_classifications(predictions_prob)\n",
    "\n",
    "calculate_accuracy(predictions_classifications, y_train[validation_idxs].reset_index(drop=True).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "84fd1ff0-a399-46e1-a634-3d1cef07f476",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.002875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.038355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  178.000000\n",
       "mean     0.000215\n",
       "std      0.002875\n",
       "min      0.000000\n",
       "25%      0.000000\n",
       "50%      0.000000\n",
       "75%      0.000000\n",
       "max      0.038355"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(predictions_prob.detach().numpy()).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8041ab2-4c43-4cd3-ac4f-5ec9a427d757",
   "metadata": {},
   "source": [
    "### 3.6. Submit to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6dc8dee1-365e-49ba-80c6-93c7cb9bdd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_prob = calculate_predictions_nn(test_tensor, weights)\n",
    "test_predictions_classifications = calculate_predicted_classifications(test_predictions_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b3469c5b-110d-4095-9c91-a4dc626717c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418,)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions_classifications.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fd565bcb-08dc-4feb-b201-a5466a5c2ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_903119/2927466126.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  output_df['Survived'] = test_predictions_classifications\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = test_df[['PassengerId']]\n",
    "output_df['Survived'] = test_predictions_classifications\n",
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "34dfef5f-09fa-4329-bcae-f5f1a7d36483",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv('nn_model_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d749b0be-3a9e-4c58-987a-1449aafb6b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived\n",
       "0    418\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df['Survived'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce117036-7967-4d8e-baf8-1691610d175c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
