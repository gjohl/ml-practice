{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ab89eef-9c93-43f3-8665-56c9efbd85c7",
   "metadata": {},
   "source": [
    "# Lesson 5: Linear model and Neural Network From Scratch\n",
    "A notebook based on Lesson 5 of the Fast AI course.\n",
    "\n",
    "In this notebook, we will train a linear model from scratch using basic pytorch tensors.\n",
    "This follows a similar process to the spreadsheet approach from Lesson 3, [here](https://docs.google.com/spreadsheets/d/1hma4bTEFuiS483djqE5dPoLlbsSQOTioqMzsesZGUGI/edit?usp=sharing)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78bc27d-00bf-49bf-8bcf-1c338adb131a",
   "metadata": {},
   "source": [
    "## 0. Set up\n",
    "Download the source data from Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "681808f6-761a-44d6-b5ae-831868fa47a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/gurp/.kaggle/kaggle.json'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "\n",
    "import kaggle\n",
    "\n",
    "\n",
    "DATA_DIR = Path().absolute().parents[1] / 'datasets' / 'fastai' / 'lesson5'\n",
    "DATA_FNAME = 'titanic'\n",
    "\n",
    "if not DATA_DIR.exists():\n",
    "    kaggle.api.competition_download_cli(str(DATA_FNAME), path=DATA_DIR)\n",
    "    zipfile.ZipFile(f'{DATA_DIR / DATA_FNAME}.zip').extractall(DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d362e1d-1b70-4703-b9e4-f837c9cd5ec0",
   "metadata": {},
   "source": [
    "## 1. Feature engineering\n",
    "Clean the data, impute missing values and calcualte some meaningful features to train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57c0eeed-6ea9-4d81-96a6-03be670a30a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7be02555-64eb-4c8a-a781-f112f55f0e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(DATA_DIR / 'train.csv')\n",
    "test_df = pd.read_csv(DATA_DIR / 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e621991-b3e7-4848-8d08-76d94f73f715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11d927fc-a98b-4c08-b9dd-0abcc4cf4d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_cols = ['AgeNorm', 'SibSp', 'Parch', 'Family', 'Alone', 'LogFare', 'TicketFreq']\n",
    "categorical_cols = ['Pclass', 'Sex', 'Embarked', 'Deck', 'Title']\n",
    "    \n",
    "\n",
    "def calculate_features(df):\n",
    "    \"\"\"Add engineered features for the titanic dataset.\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Min-max scaler on Age\n",
    "    df['AgeNorm'] = df['Age'].fillna(df['Age'].mean()) / df['Age'].max()\n",
    "\n",
    "    # Log of Fares to tame the long tail\n",
    "    df['LogFare'] = np.log1p(df['Fare'])\n",
    "\n",
    "    # Group Cabins by Deck\n",
    "    df['Cabin'].fillna(df['Cabin'].mode().iloc[0], inplace=True)\n",
    "    df['Deck'] = df['Cabin'].str[0].map(dict(A=\"ABC\", B=\"ABC\", C=\"ABC\", D=\"DE\", E=\"DE\", F=\"FG\", G=\"FG\")).fillna(\"Other\")\n",
    "\n",
    "    # Features based on family members\n",
    "    df['Family'] = df['SibSp'] + df['Parch']\n",
    "    df['Alone'] = df['Family'] == 0\n",
    "\n",
    "    # Did multiple people travel on the same ticket\n",
    "    df['TicketFreq'] = df.groupby('Ticket')['Ticket'].transform('count')\n",
    "\n",
    "    # Use just the title portion of the Name field\n",
    "    df['Title'] = df['Name'].str.split(', ', expand=True)[1].str.split('. ', expand=True)[0]\n",
    "    df['Title'] = df['Title'].map({'Mr': 'Mr', 'Miss': 'Miss', 'Mrs': 'Mrs', 'Master': 'Master'}).fillna(\"Other\")\n",
    "\n",
    "    # One-hot encode categorical variables\n",
    "    categorical_cols = ['Pclass', 'Sex', 'Embarked', 'Deck', 'Title']\n",
    "    df['Embarked'].fillna(df['Embarked'].mode().iloc[0], inplace=True)\n",
    "    df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "    df['const'] = 1\n",
    "\n",
    "    # Filter the output columns\n",
    "    categorical_cols_output = []\n",
    "    for cat_col in categorical_cols:\n",
    "        categorical_cols_output.extend([k for k in df.columns if f'{cat_col}_' in k])\n",
    "    output_cols = continuous_cols + categorical_cols_output\n",
    "\n",
    "    return df[output_cols] * 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00fe4391-7b2c-448f-9d00-5876169a02fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AgeNorm</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Family</th>\n",
       "      <th>Alone</th>\n",
       "      <th>LogFare</th>\n",
       "      <th>TicketFreq</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Deck_DE</th>\n",
       "      <th>Deck_FG</th>\n",
       "      <th>Deck_Other</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.110213</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.280593</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.188856</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.990834</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.202765</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AgeNorm  SibSp  Parch  Family  Alone   LogFare  TicketFreq  Pclass_2  \\\n",
       "0   0.2750    1.0    0.0     1.0    0.0  2.110213         1.0       0.0   \n",
       "1   0.4750    1.0    0.0     1.0    0.0  4.280593         1.0       0.0   \n",
       "2   0.3250    0.0    0.0     0.0    1.0  2.188856         1.0       0.0   \n",
       "3   0.4375    1.0    0.0     1.0    0.0  3.990834         2.0       0.0   \n",
       "4   0.4375    0.0    0.0     0.0    1.0  2.202765         1.0       0.0   \n",
       "\n",
       "   Pclass_3  Sex_male  Embarked_Q  Embarked_S  Deck_DE  Deck_FG  Deck_Other  \\\n",
       "0       1.0       1.0         0.0         1.0      0.0      0.0         0.0   \n",
       "1       0.0       0.0         0.0         0.0      0.0      0.0         0.0   \n",
       "2       1.0       0.0         0.0         1.0      0.0      0.0         0.0   \n",
       "3       0.0       0.0         0.0         1.0      0.0      0.0         0.0   \n",
       "4       1.0       1.0         0.0         1.0      0.0      0.0         0.0   \n",
       "\n",
       "   Title_Miss  Title_Mr  Title_Mrs  Title_Other  \n",
       "0         0.0       1.0        0.0          0.0  \n",
       "1         0.0       0.0        1.0          0.0  \n",
       "2         1.0       0.0        0.0          0.0  \n",
       "3         0.0       0.0        1.0          0.0  \n",
       "4         0.0       1.0        0.0          0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = calculate_features(train_df)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1511c571-db9d-4917-b9da-6df96953d4a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    1.0\n",
       "2    1.0\n",
       "3    1.0\n",
       "4    0.0\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train_df['Survived'] * 1.\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c80bde4-364d-4ded-88e0-76a2ff66af36",
   "metadata": {},
   "source": [
    "## 2. Train a linear model\n",
    "Train a linear model \"from scratch\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c85170-e957-4068-a08b-6400d57cc4e1",
   "metadata": {},
   "source": [
    "### 2.1. Initialise random weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a078dd8-8ce5-407b-9536-a5aa4fbcd510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66cf138b-99e0-46b1-afab-def6f0565950",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = X_train.shape[1]\n",
    "num_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5aa109f-c281-4977-9b37-de4693e9f135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_weights(num_layers, num_features):\n",
    "    weights = torch.rand([num_layers, num_features]) - 0.5\n",
    "    weights.requires_grad_()\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afc9370e-061d-47f8-9702-04fd5f4379aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0361, -0.4260, -0.0935,  0.3016, -0.4976, -0.0761, -0.4685,  0.4407,\n",
       "          0.3553,  0.2118, -0.1979, -0.4992,  0.2750, -0.0418,  0.1658,  0.3786,\n",
       "          0.2520, -0.1228,  0.4572]], requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = initialise_weights(num_layers, num_features)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de7e8a8-a98b-44a3-9e83-a37aef06c02b",
   "metadata": {},
   "source": [
    "### 2.2. Define the model and loss function\n",
    "This is just a linear model with MAE loss function to start with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbd56beb-28d1-402f-9aa3-abd7a450de4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(predictions, actual):\n",
    "    \"\"\"Mean Absolute Error\"\"\"\n",
    "    return (predictions - actual).abs().mean()\n",
    "    \n",
    "\n",
    "def calculate_predictions(features, weights):\n",
    "    \"\"\"Linear model to calculate predictions.\"\"\"\n",
    "    return features @ weights.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bb50f37-d43f-4449-9569-2d3a4ede3d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2750, 1.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
       "        [0.4750, 1.0000, 0.0000,  ..., 0.0000, 1.0000, 0.0000],\n",
       "        [0.3250, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.3712, 1.0000, 2.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.3250, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
       "        [0.4000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_independent = torch.tensor(X_train.values, dtype=torch.float)\n",
    "t_independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a616406-f6b2-490e-8d43-4a3c5e297b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
       "        1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
       "        0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "        0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
       "        1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
       "        0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
       "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
       "        1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1.,\n",
       "        0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
       "        0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0.,\n",
       "        0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0.,\n",
       "        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "        1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1.,\n",
       "        1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
       "        1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
       "        0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
       "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,\n",
       "        1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
       "        1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
       "        0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
       "        1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1.,\n",
       "        0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
       "        1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0.,\n",
       "        0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 1., 0.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_dependent = torch.tensor(y_train.values, dtype=torch.float)\n",
    "t_dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37c9b42e-2eb3-4ad8-8790-e22ea61ead66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4434],\n",
       "        [-1.0585],\n",
       "        [-0.9097],\n",
       "        [-2.0028],\n",
       "        [-0.8296]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = calculate_predictions(t_independent, weights)\n",
    "preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "104fee8a-2978-4f87-863a-9c1835540da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([891, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7fae27ae-9256-45e1-9d18-6dc5ded576c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4634, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = calculate_loss(preds, t_dependent)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc6c748-34ad-4700-a9ce-f6c186cfba77",
   "metadata": {},
   "source": [
    "### 2.3 Gradient descent step\n",
    "Calculate an epoch of gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2df871a-fe9a-4e1b-ad71-378f41c65a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22c71c3f-82a1-416c-afc1-3ff1b0862709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0293, -0.2715,  0.0638,  0.0363, -0.0516, -0.3514, -0.1332,  0.2533,\n",
       "          0.1105, -0.2790, -0.2712, -0.2183,  0.0045, -0.4709,  0.4644,  0.3106,\n",
       "          0.3412,  0.2424, -0.1394]], requires_grad=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = initialise_weights(num_layers, num_features)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cce86ec0-189b-46dd-b0eb-5ef65c240046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7557, grad_fn=<MeanBackward0>)\n",
      "tensor(1.7403)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the loss using the current weights\n",
    "preds = calculate_predictions(t_independent, weights)\n",
    "loss = calculate_loss(preds, t_dependent)\n",
    "print(loss)\n",
    "\n",
    "# Calculate the gradients\n",
    "loss.backward()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Take a gradient descent step\n",
    "    weights.subtract_(weights.grad * LEARNING_RATE)\n",
    "\n",
    "    # Reset gradients ready for the next step. Otherwise pytorch adds gradients on the next epoch.\n",
    "    weights.grad.zero_()\n",
    "\n",
    "    preds = calculate_predictions(t_independent, weights)\n",
    "    loss = calculate_loss(preds, t_dependent)\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8a8dee-cd85-48c7-b886-4f5ba3977683",
   "metadata": {},
   "source": [
    "The loss reduced as we hoped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd567b53-f220-4ae0-b5bf-30978436f36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_epoch(weights, t_independent, t_dependent, loss=None):\n",
    "    \"\"\"Run one epoch and return the weights and loss\"\"\"\n",
    "    \n",
    "    if loss is None:\n",
    "        # Use the loss from the previous epoch if passed in, otherwise calculate the loss using the current weights\n",
    "        preds = calculate_predictions(t_independent, weights)\n",
    "        loss = calculate_loss(preds, t_dependent)\n",
    "\n",
    "    # Calculate the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Take a gradient descent step\n",
    "        weights.subtract_(weights.grad * LEARNING_RATE)\n",
    "\n",
    "        # Reset gradients ready for the next step. Otherwise pytorch adds gradients on the next epoch.\n",
    "        weights.grad.zero_()\n",
    "\n",
    "    preds = calculate_predictions(t_independent, weights)\n",
    "    loss = calculate_loss(preds, t_dependent)\n",
    "\n",
    "    return weights, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2ec45af-dbe6-43d6-b821-527940c99b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1442,  0.1342, -0.0528, -0.1240,  0.3205,  0.4128, -0.0689,  0.4535,\n",
       "          0.1407, -0.2449,  0.2137, -0.4818,  0.1861,  0.1985, -0.2021,  0.2186,\n",
       "         -0.4276, -0.1588, -0.0288]], requires_grad=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = initialise_weights(num_layers, num_features)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4564fca-c70a-4b4c-951c-60e6180b361b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6520402431488037\n"
     ]
    }
   ],
   "source": [
    "weights, loss = calculate_epoch(weights, t_independent, t_dependent, loss=None)\n",
    "print(float(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf0c0f89-201a-4382-97bc-ebde88b679b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.650128185749054\n"
     ]
    }
   ],
   "source": [
    "weights, loss = calculate_epoch(weights, t_independent, t_dependent, loss=loss)\n",
    "print(float(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dbaedfc6-d314-4162-83c0-7098c3690461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.648271918296814\n"
     ]
    }
   ],
   "source": [
    "weights, loss = calculate_epoch(weights, t_independent, t_dependent, loss=loss)\n",
    "print(float(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "185d9042-a8da-4f19-aea3-84c05f467f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6465025544166565\n"
     ]
    }
   ],
   "source": [
    "weights, loss = calculate_epoch(weights, t_independent, t_dependent, loss=loss)\n",
    "print(float(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ab1767d-cf2d-4c30-9b64-a7ef5cf9b638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6447898149490356\n"
     ]
    }
   ],
   "source": [
    "weights, loss = calculate_epoch(weights, t_independent, t_dependent, loss=loss)\n",
    "print(float(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938e1c0d-72f9-4008-9a1a-3e6beafe8944",
   "metadata": {},
   "source": [
    "### 2.4. Loop through multiple epochs\n",
    "Run multiple epochs of gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fcac991b-2ee1-43b8-8f14-a74fc682f2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 20\n",
    "LEARNING_RATE = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "84a043d2-8a61-423f-b075-08d5fc4e20d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2274833917617798\n",
      "0.6289820671081543\n",
      "0.5323521494865417\n",
      "0.5231783986091614\n",
      "0.5187276005744934\n",
      "0.5152965784072876\n",
      "0.5122267007827759\n",
      "0.5097238421440125\n",
      "0.5074202418327332\n",
      "0.5051789879798889\n",
      "0.5029891729354858\n",
      "0.5008192658424377\n",
      "0.4987630844116211\n",
      "0.49666815996170044\n",
      "0.4947459101676941\n",
      "0.49274128675460815\n",
      "0.49112579226493835\n",
      "0.4897114932537079\n",
      "0.48834651708602905\n",
      "0.48723021149635315\n"
     ]
    }
   ],
   "source": [
    "weights = initialise_weights(num_layers, num_features)\n",
    "loss = None\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    weights, loss = calculate_epoch(weights, t_independent, t_dependent, loss=loss)\n",
    "    print(float(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ce1c277-2770-4f7f-bd37-22125e8f46a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear_model(t_independent, t_dependent, num_layers, num_epochs):\n",
    "    num_features = t_independent.shape[1]\n",
    "    weights = initialise_weights(num_layers, num_features)\n",
    "    loss = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        weights, loss = calculate_epoch(weights, t_independent, t_dependent, loss=loss)\n",
    "        if epoch % 10 == 0: print(epoch, float(loss))\n",
    "\n",
    "    return weights, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3d278fd0-c8ca-48ba-85ea-e123c3ed140d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5080814361572266\n",
      "10 0.4840608239173889\n",
      "20 0.46877947449684143\n",
      "30 0.45717185735702515\n",
      "40 0.4491163492202759\n",
      "50 0.44316354393959045\n",
      "60 0.4385168254375458\n",
      "70 0.43420925736427307\n",
      "80 0.43203839659690857\n",
      "90 0.4301871061325073\n"
     ]
    }
   ],
   "source": [
    "weights, loss = train_linear_model(t_independent, t_dependent, num_layers=1, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "75d37ca2-1e95-46e7-bd5f-61921f3a39f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AgeNorm': tensor(-0.3547),\n",
       " 'SibSp': tensor(-0.2115),\n",
       " 'Parch': tensor(-0.1660),\n",
       " 'Family': tensor(0.2110),\n",
       " 'Alone': tensor(0.0404),\n",
       " 'LogFare': tensor(0.0238),\n",
       " 'TicketFreq': tensor(-0.0129),\n",
       " 'Pclass_2': tensor(0.2006),\n",
       " 'Pclass_3': tensor(0.1722),\n",
       " 'Sex_male': tensor(-0.0697),\n",
       " 'Embarked_Q': tensor(-0.3245),\n",
       " 'Embarked_S': tensor(-0.2680),\n",
       " 'Deck_DE': tensor(0.2622),\n",
       " 'Deck_FG': tensor(-0.1807),\n",
       " 'Deck_Other': tensor(0.2796),\n",
       " 'Title_Miss': tensor(0.1851),\n",
       " 'Title_Mr': tensor(0.2615),\n",
       " 'Title_Mrs': tensor(0.2468),\n",
       " 'Title_Other': tensor(0.4242)}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(X_train.columns, *weights.requires_grad_(False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d690d43-3048-4a82-96e0-12d044d4633f",
   "metadata": {},
   "source": [
    "### 2.5. Measure accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7783232b-02c2-4a1f-971e-d7bb34c8ebca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(predictions, actuals):\n",
    "    return (predictions == actuals).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d757c69c-203d-4858-8d3a-00ceb8c3896e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6172839506172839"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_prob = calculate_predictions(t_independent, weights)\n",
    "predictions_classifications = predictions_prob > 0.5\n",
    "predictions_classifications = pd.Series(predictions_classifications.squeeze()).astype(int)\n",
    "\n",
    "calculate_accuracy(predictions_classifications, y_train.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3801c060-f566-42f3-9300-965b88f698c0",
   "metadata": {},
   "source": [
    "### 2.6. Add a sigmoid\n",
    "The output layer of a binary classifier should be bounded between 0 and 1.\n",
    "A sigmoid function handles this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f4ccc76d-d105-4e13-b5c9-319a1429cb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_predictions(features, weights):\n",
    "    \"\"\"Linear model to calculate predictions.\"\"\"\n",
    "    return torch.sigmoid(features @ weights.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5790054d-26ea-4904-bb8e-6b22da23e3b6",
   "metadata": {},
   "source": [
    "### 2.7 Train the model on a training set and compare validation set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "754c6476-58cf-4791-a5e7-6b6e6b189239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "296d3800-56f5-4f0f-810e-3704cec1d540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_set_split(data, validation_pct):\n",
    "    \"\"\"Given a collection of input data, return the indexes of the training and validation sets.\"\"\"\n",
    "    num_observations = data.shape[0]\n",
    "    validation_size = int(num_observations * validation_pct)\n",
    "    validation_idxs = sorted(random.sample(range(num_observations), validation_size))\n",
    "    training_idxs = list(set(range(num_observations)).difference(set(validation_idxs)))\n",
    "    return training_idxs, validation_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b672908a-de46-4887-8ada-7586c975104b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_idxs, validation_idxs = validation_set_split(t_independent, validation_pct=0.2)\n",
    "\n",
    "def train_linear_model(t_independent, t_dependent, num_layers, num_epochs, validation_pct):\n",
    "    # Split training/validation data\n",
    "    X_train = t_independent[training_idxs]\n",
    "    y_train = t_dependent[training_idxs]\n",
    "    X_validation = t_independent[validation_idxs]\n",
    "    y_validation = t_dependent[validation_idxs]\n",
    "\n",
    "    # Initialise weights\n",
    "    num_features = t_independent.shape[1]\n",
    "    weights = initialise_weights(num_layers, num_features)\n",
    "    loss = None\n",
    "\n",
    "    # Gradient descent\n",
    "    for epoch in range(num_epochs):\n",
    "        weights, loss = calculate_epoch(weights, X_train, y_train, loss=loss)\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            validation_predictions = calculate_predictions(X_validation, weights)\n",
    "            validation_loss = calculate_loss(validation_predictions, y_validation)\n",
    "            print(epoch, float(validation_loss))\n",
    "\n",
    "    return weights, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1e72dd31-0887-4e77-8785-cb77dafd5eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.4971848428249359\n",
      "10 0.49094733595848083\n",
      "20 0.4856831431388855\n",
      "30 0.48164814710617065\n",
      "40 0.4786932170391083\n",
      "50 0.47654294967651367\n"
     ]
    }
   ],
   "source": [
    "weights, loss = train_linear_model(t_independent, t_dependent, num_layers=1, num_epochs=51, validation_pct=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "173929b7-19e0-4826-b330-130b8e48a2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_predicted_classifications(predictions_prob):\n",
    "    predictions_classifications = predictions_prob > 0.5\n",
    "    return pd.Series(predictions_classifications.squeeze()).astype(int)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "405713ee-a4f4-434f-9f81-cfb5e08ad762",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5337078651685393"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_prob = calculate_predictions(t_independent[validation_idxs], weights)\n",
    "predictions_classifications = calculate_predicted_classifications(predictions_prob)\n",
    "\n",
    "calculate_accuracy(predictions_classifications, y_train[validation_idxs].reset_index(drop=True).astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b716703a-9c2f-4279-816e-b98fce1de87c",
   "metadata": {},
   "source": [
    "### 2.8. Submit to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d143af00-9abd-4abf-997c-7df90b825696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AgeNorm</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Family</th>\n",
       "      <th>Alone</th>\n",
       "      <th>LogFare</th>\n",
       "      <th>TicketFreq</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Deck_DE</th>\n",
       "      <th>Deck_FG</th>\n",
       "      <th>Deck_Other</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.453947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.178064</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.618421</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.369075</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.355263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.268252</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.289474</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.586824</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>0.398324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.202765</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>0.513158</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.699571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>0.506579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.110213</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>0.398324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.202765</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>0.398324</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.150952</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AgeNorm  SibSp  Parch  Family  Alone   LogFare  TicketFreq  Pclass_2  \\\n",
       "0    0.453947    0.0    0.0     0.0    1.0  2.178064         1.0       0.0   \n",
       "1    0.618421    1.0    0.0     1.0    0.0  2.079442         1.0       0.0   \n",
       "2    0.815789    0.0    0.0     0.0    1.0  2.369075         1.0       1.0   \n",
       "3    0.355263    0.0    0.0     0.0    1.0  2.268252         1.0       0.0   \n",
       "4    0.289474    1.0    1.0     2.0    0.0  2.586824         1.0       0.0   \n",
       "..        ...    ...    ...     ...    ...       ...         ...       ...   \n",
       "413  0.398324    0.0    0.0     0.0    1.0  2.202765         1.0       0.0   \n",
       "414  0.513158    0.0    0.0     0.0    1.0  4.699571         1.0       0.0   \n",
       "415  0.506579    0.0    0.0     0.0    1.0  2.110213         1.0       0.0   \n",
       "416  0.398324    0.0    0.0     0.0    1.0  2.202765         1.0       0.0   \n",
       "417  0.398324    1.0    1.0     2.0    0.0  3.150952         1.0       0.0   \n",
       "\n",
       "     Pclass_3  Sex_male  Embarked_Q  Embarked_S  Deck_DE  Deck_FG  Deck_Other  \\\n",
       "0         1.0       1.0         1.0         0.0      0.0      0.0         0.0   \n",
       "1         1.0       0.0         0.0         1.0      0.0      0.0         0.0   \n",
       "2         0.0       1.0         1.0         0.0      0.0      0.0         0.0   \n",
       "3         1.0       1.0         0.0         1.0      0.0      0.0         0.0   \n",
       "4         1.0       0.0         0.0         1.0      0.0      0.0         0.0   \n",
       "..        ...       ...         ...         ...      ...      ...         ...   \n",
       "413       1.0       1.0         0.0         1.0      0.0      0.0         0.0   \n",
       "414       0.0       0.0         0.0         0.0      0.0      0.0         0.0   \n",
       "415       1.0       1.0         0.0         1.0      0.0      0.0         0.0   \n",
       "416       1.0       1.0         0.0         1.0      0.0      0.0         0.0   \n",
       "417       1.0       1.0         0.0         0.0      0.0      0.0         0.0   \n",
       "\n",
       "     Title_Miss  Title_Mr  Title_Mrs  Title_Other  \n",
       "0           0.0       1.0        0.0          0.0  \n",
       "1           0.0       0.0        1.0          0.0  \n",
       "2           0.0       1.0        0.0          0.0  \n",
       "3           0.0       1.0        0.0          0.0  \n",
       "4           0.0       0.0        1.0          0.0  \n",
       "..          ...       ...        ...          ...  \n",
       "413         0.0       1.0        0.0          0.0  \n",
       "414         0.0       0.0        0.0          1.0  \n",
       "415         0.0       1.0        0.0          0.0  \n",
       "416         0.0       1.0        0.0          0.0  \n",
       "417         0.0       0.0        0.0          0.0  \n",
       "\n",
       "[418 rows x 19 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feature_df = calculate_features(test_df)\n",
    "test_feature_df['Deck_Other'] = 0.\n",
    "test_feature_df = test_feature_df[X_train.columns]\n",
    "test_feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e1b32135-4ff9-4ef3-8d8a-99d01193d31f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4539, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
       "        [0.6184, 1.0000, 0.0000,  ..., 0.0000, 1.0000, 0.0000],\n",
       "        [0.8158, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.5066, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
       "        [0.3983, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
       "        [0.3983, 1.0000, 1.0000,  ..., 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tensor = torch.tensor(test_feature_df.values, dtype=torch.float)\n",
    "test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "da8a6550-9c8c-4c99-9c0c-2ad28604bdca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>male</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                          Name  \\\n",
       "0            892       3                              Kelly, Mr. James   \n",
       "1            893       3              Wilkes, Mrs. James (Ellen Needs)   \n",
       "2            894       2                     Myles, Mr. Thomas Francis   \n",
       "3            895       3                              Wirz, Mr. Albert   \n",
       "4            896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n",
       "..           ...     ...                                           ...   \n",
       "413         1305       3                            Spector, Mr. Woolf   \n",
       "414         1306       1                  Oliva y Ocana, Dona. Fermina   \n",
       "415         1307       3                  Saether, Mr. Simon Sivertsen   \n",
       "416         1308       3                           Ware, Mr. Frederick   \n",
       "417         1309       3                      Peter, Master. Michael J   \n",
       "\n",
       "        Sex   Age  SibSp  Parch              Ticket      Fare Cabin Embarked  \n",
       "0      male  34.5      0      0              330911    7.8292   NaN        Q  \n",
       "1    female  47.0      1      0              363272    7.0000   NaN        S  \n",
       "2      male  62.0      0      0              240276    9.6875   NaN        Q  \n",
       "3      male  27.0      0      0              315154    8.6625   NaN        S  \n",
       "4    female  22.0      1      1             3101298   12.2875   NaN        S  \n",
       "..      ...   ...    ...    ...                 ...       ...   ...      ...  \n",
       "413    male   NaN      0      0           A.5. 3236    8.0500   NaN        S  \n",
       "414  female  39.0      0      0            PC 17758  108.9000  C105        C  \n",
       "415    male  38.5      0      0  SOTON/O.Q. 3101262    7.2500   NaN        S  \n",
       "416    male   NaN      0      0              359309    8.0500   NaN        S  \n",
       "417    male   NaN      1      1                2668   22.3583   NaN        C  \n",
       "\n",
       "[418 rows x 11 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8c0dfac5-aba8-4d72-b5ba-03de53b4116c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_prob = calculate_predictions(test_tensor, weights)\n",
    "test_predictions_classifications = calculate_predicted_classifications(test_predictions_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9231e151-35bc-4b42-b76a-f12f57133368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418,)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions_classifications.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4927d037-d120-4097-8105-e400e9d9eb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_342567/2927466126.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  output_df['Survived'] = test_predictions_classifications\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = test_df[['PassengerId']]\n",
    "output_df['Survived'] = test_predictions_classifications\n",
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "41a5fd04-8b70-46ca-9c54-cd0d51164402",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv('linear_model_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "05d09953-dfb5-4d32-a194-1a5506a9e61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived\n",
       "0    418\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df['Survived'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51abcb8-6587-4498-8d78-c5f4f5b9181e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
