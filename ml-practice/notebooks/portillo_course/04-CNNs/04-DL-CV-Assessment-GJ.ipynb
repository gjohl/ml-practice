{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.pieriandata.com\"><img src=\"../Pierian_Data_Logo.PNG\"></a>\n",
    "<strong><center>Copyright by Pierian Data Inc.</center></strong> \n",
    "<strong><center>Created by Jose Marcial Portilla.</center></strong>\n",
    "# Deep Learning for Image Classification Assessment\n",
    "\n",
    "\n",
    "Welcome to your assessment! Follow the instructions in bold below to complete the assessment.\n",
    "\n",
    "If you get stuck, check out the solutions video and notebook. (Make sure to run the solutions notebook before posting a question to the QA forum please, thanks!)\n",
    "\n",
    "------------\n",
    "\n",
    "## The Challenge\n",
    "\n",
    "**Your task is to build an image classifier with Keras and Convolutional Neural Networks for the Fashion MNIST dataset. This data set includes 10 labels of different clothing types with 28 by 28 *grayscale* images. There is a training set of 60,000 images and 10,000 test images.**\n",
    "\n",
    "    Label\tDescription\n",
    "    0\t    T-shirt/top\n",
    "    1\t    Trouser\n",
    "    2\t    Pullover\n",
    "    3\t    Dress\n",
    "    4\t    Coat\n",
    "    5\t    Sandal\n",
    "    6\t    Shirt\n",
    "    7\t    Sneaker\n",
    "    8\t    Bag\n",
    "    9\t    Ankle boot\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "**TASK 1: Run the code below to download the dataset using Keras.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-28 20:10:31.028984: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-02-28 20:10:31.066626: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-02-28 20:10:31.067239: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-28 20:10:31.756419: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 12s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Data\n",
    "\n",
    "**TASK 2: Use matplotlib to view an image from the data set. It can be any image from the data set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f676f1a4310>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2bf7c9c1d68>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Data\n",
    "\n",
    "**TASK 3: Normalize the X train and X test data by dividing by the max value of the image arrays.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4: Reshape the X arrays to include a 4 dimension of the single channel. Similar to what we did for the numbers MNIST data set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_size = (x_train.shape[1], x_train.shape[2])\n",
    "num_train = x_train.shape[0]\n",
    "num_test = x_test.shape[0]\n",
    "color_channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(num_train, img_size[0], img_size[1], color_channels)\n",
    "x_test = x_test.reshape(num_test, img_size[0], img_size[1], color_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 5: Convert the y_train and y_test values to be one-hot encoded for categorical analysis by Keras.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model\n",
    "\n",
    "**TASK 5: Use Keras to create a model consisting of at least the following layers (but feel free to experiment):**\n",
    "\n",
    "* 2D Convolutional Layer, filters=32 and kernel_size=(4,4)\n",
    "* Pooling Layer where pool_size = (2,2)\n",
    "\n",
    "* Flatten Layer\n",
    "* Dense Layer (128 Neurons, but feel free to play around with this value), RELU activation\n",
    "\n",
    "* Final Dense Layer of 10 Neurons with a softmax activation\n",
    "\n",
    "**Then compile the model with these parameters: loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_time = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "log_dir = os.path.join(os.getcwd(), 'project_logs', log_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-28 20:28:55.480122: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2023-02-28 20:28:55.480190: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2023-02-28 20:28:55.482621: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "board = TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    write_graph=True,\n",
    "    write_images=True,\n",
    "    update_freq='epoch',\n",
    "    profile_batch=2,\n",
    "    embeddings_freq=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Conv-pool layer pairs\n",
    "model.add(Conv2D(filters=32, kernel_size=(4,4)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "          \n",
    "model.add(Conv2D(filters=16, kernel_size=(8,8)))\n",
    "model.add(MaxPool2D(pool_size=(4,4)))\n",
    "\n",
    "# Flatten the output for Dense layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# # Multiple Hidden layers with dropout\n",
    "model.add(Dense(28*28, activation='relu'))\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "# # Output layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Problem setup\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 25, 25, 32)        544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 591,786\n",
      "Trainable params: 591,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "**TASK 6: Train/Fit the model to the x_train set. Amount of epochs is up to you.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  23/1875 [..............................] - ETA: 13s - loss: 1.9000 - accuracy: 0.2880"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-28 20:39:46.999657: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2023-02-28 20:39:46.999673: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2023-02-28 20:39:47.009299: I tensorflow/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2023-02-28 20:39:47.010218: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.5492 - accuracy: 0.8005 - val_loss: 0.4004 - val_accuracy: 0.8604\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.3942 - accuracy: 0.8616 - val_loss: 0.4076 - val_accuracy: 0.8599\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.3624 - accuracy: 0.8732 - val_loss: 0.3921 - val_accuracy: 0.8658\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.3507 - accuracy: 0.8785 - val_loss: 0.4186 - val_accuracy: 0.8466\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.3437 - accuracy: 0.8802 - val_loss: 0.4197 - val_accuracy: 0.8568\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.3431 - accuracy: 0.8817 - val_loss: 0.4253 - val_accuracy: 0.8488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f67508307d0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          epochs=10,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[early_stopping, board])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 25, 25, 32)        544       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 12, 12, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 5, 5, 16)          32784     \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 1, 1, 16)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 784)               13328     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               100480    \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 148,426\n",
      "Trainable params: 148,426\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1802 - acc: 0.9365\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1679 - acc: 0.9395\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.1579 - acc: 0.9439\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1502 - acc: 0.9469\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1427 - acc: 0.9496\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1397 - acc: 0.9523\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1312 - acc: 0.9551\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1274 - acc: 0.9559\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1238 - acc: 0.9582\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1201 - acc: 0.9588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c18a60e400>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Model\n",
    "\n",
    "**TASK 7: Show the accuracy,precision,recall,f1-score the model achieved on the x_test data set. Keep in mind, there are quite a few ways to do this, but we recommend following the same procedure we showed in the MNIST lecture.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction_prob = model.predict(x_test)\n",
    "y_pred = np.argmax(prediction_prob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1, ..., 8, 1, 5])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.72      0.78      1000\n",
      "           1       0.99      0.95      0.97      1000\n",
      "           2       0.81      0.76      0.79      1000\n",
      "           3       0.77      0.95      0.85      1000\n",
      "           4       0.81      0.76      0.78      1000\n",
      "           5       0.96      0.92      0.94      1000\n",
      "           6       0.60      0.68      0.64      1000\n",
      "           7       0.82      0.99      0.89      1000\n",
      "           8       0.98      0.92      0.95      1000\n",
      "           9       0.98      0.86      0.92      1000\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.86      0.85      0.85     10000\n",
      "weighted avg       0.86      0.85      0.85     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_test, axis=1), y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_img = x_test[69].reshape(1, img_size[0], img_size[1], color_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "img_pred = model.predict(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.4021464e-18, 1.0799555e-22, 1.4902564e-16, 8.6995834e-18,\n",
       "        1.3161547e-17, 3.4008737e-17, 2.4670478e-16, 3.0929387e-19,\n",
       "        1.0000000e+00, 1.7890902e-22]], dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(img_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[69].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_test[69].reshape(10, 1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.85      0.85      1000\n",
      "          1       0.99      0.97      0.98      1000\n",
      "          2       0.88      0.83      0.85      1000\n",
      "          3       0.91      0.91      0.91      1000\n",
      "          4       0.83      0.88      0.85      1000\n",
      "          5       0.97      0.98      0.98      1000\n",
      "          6       0.73      0.76      0.74      1000\n",
      "          7       0.95      0.97      0.96      1000\n",
      "          8       0.99      0.97      0.98      1000\n",
      "          9       0.98      0.94      0.96      1000\n",
      "\n",
      "avg / total       0.91      0.91      0.91     10000\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
